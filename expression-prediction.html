<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />


<meta name="author" content="Anshul Kundaje, Oana Ursu, and Sean Davis" />


<title>Expression Prediction</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
<link href="site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />
<link href="site_libs/ionicons-2.0.1/css/ionicons.min.css" rel="stylesheet" />

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>

<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->



<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = false;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}

.tocify-subheader {
  display: inline;
}
.tocify-subheader .tocify-item {
  font-size: 0.95em;
}

</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-inverse  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">seandavi(s12): Courses and Tutorials</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="about.html">About</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="setup.html">
    <span class="fa fa-cogs"></span>
     
    setup
  </a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="ion ion-easel"></span>
     
    Slides
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="motivation_for_R_slides.html">Motivation for using R</a>
    </li>
    <li>
      <a href="http://bit.ly/bioc_cshl_2018">Introduction to Bioconductor</a>
    </li>
    <li>
      <a href="MachineLearningSlides.html">Machine Learning hands-on</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-question fa-lg"></span>
     
    Misc.
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="further_resources.html">Further resources</a>
    </li>
    <li>
      <a href="https://github.com/seandavi/ITR">Source code for this site</a>
    </li>
    <li>
      <a href="https://github.com/seandavi/ITR/archive/master.zip">Download materials</a>
    </li>
  </ul>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Expression Prediction</h1>
<h4 class="author">Anshul Kundaje, Oana Ursu, and Sean Davis</h4>
<h4 class="date">7/8/2018</h4>

</div>


<div id="install-packages" class="section level1">
<h1>Install packages</h1>
<p>Do this at the beginning of the lab</p>
<pre class="r"><code>install.packages(&quot;caret&quot;, dependencies=T)
install.packages(c(&quot;randomForest&quot;, &quot;glmnet&quot;), dependencies=T)</code></pre>
<pre class="r"><code>require(caret)</code></pre>
<pre><code>## Warning in library(package, lib.loc = lib.loc, character.only = TRUE,
## logical.return = TRUE, : there is no package called &#39;caret&#39;</code></pre>
<pre class="r"><code>require(randomForest)
require(glmnet)</code></pre>
<pre><code>## Warning in library(package, lib.loc = lib.loc, character.only = TRUE,
## logical.return = TRUE, : there is no package called &#39;glmnet&#39;</code></pre>
</div>
<div id="load-the-preprocessed-data" class="section level1">
<h1>Load the preprocessed data</h1>
<pre class="r"><code>fullFeatureSet &lt;- read.table(&quot;http://seandavi.github.io/ITR/expression-prediction/features.txt&quot;);
target &lt;- scan(url(&quot;http://seandavi.github.io/ITR/expression-prediction/target.txt&quot;))</code></pre>
<p>You can see the full list of features in fullFeatureSet using:</p>
<pre class="r"><code>colnames(fullFeatureSet)</code></pre>
<pre><code>##  [1] &quot;Control&quot;  &quot;Dnase&quot;    &quot;H2az&quot;     &quot;H3k27ac&quot;  &quot;H3k27me3&quot; &quot;H3k36me3&quot;
##  [7] &quot;H3k4me1&quot;  &quot;H3k4me2&quot;  &quot;H3k4me3&quot;  &quot;H3k79me2&quot; &quot;H3k9ac&quot;   &quot;H3k9me1&quot; 
## [13] &quot;H3k9me3&quot;  &quot;H4k20me1&quot;</code></pre>
</div>
<div id="machine-learning" class="section level1">
<h1>Machine Learning</h1>
<div id="lasso" class="section level2">
<h2>Lasso</h2>
<p>In this section, we will run the lasso procedure.</p>
<pre class="r"><code>features &lt;- fullFeatureSet</code></pre>
<pre class="r"><code>library(caret)
#how to split into train/validation using cross-validation
fitControl &lt;- trainControl( 
    method=&quot;repeatedcv&quot;,
    number=10,
    ## repeated once
    repeats=1,
    verboseIter=T)</code></pre>
<p>We are going to try a number of different models, so here, we create a range of parameters to investigate.</p>
<ul>
<li>alpha - is the elasticnet mixing parameter: <span class="math display">\[(1-α)/2||β||_2^2+α||β||_1\]</span></li>
<li>lambda - is the regularization parameter governing the relative importance of minimizing error vs keeping betas small</li>
</ul>
<pre class="r"><code>lassoGrid &lt;- expand.grid(alpha=1, lambda=10^seq(-6, 0, 1))</code></pre>
<p>Now, we train the model using cross-validation to find the “best” parameters.</p>
<pre class="r"><code>lassoFit &lt;- train(features, target, method=&quot;glmnet&quot;,
                  trControl=fitControl, tuneGrid=lassoGrid)</code></pre>
<pre><code>## + Fold01.Rep1: alpha=1, lambda=1 
## - Fold01.Rep1: alpha=1, lambda=1 
## + Fold02.Rep1: alpha=1, lambda=1 
## - Fold02.Rep1: alpha=1, lambda=1 
## + Fold03.Rep1: alpha=1, lambda=1 
## - Fold03.Rep1: alpha=1, lambda=1 
## + Fold04.Rep1: alpha=1, lambda=1 
## - Fold04.Rep1: alpha=1, lambda=1 
## + Fold05.Rep1: alpha=1, lambda=1 
## - Fold05.Rep1: alpha=1, lambda=1 
## + Fold06.Rep1: alpha=1, lambda=1 
## - Fold06.Rep1: alpha=1, lambda=1 
## + Fold07.Rep1: alpha=1, lambda=1 
## - Fold07.Rep1: alpha=1, lambda=1 
## + Fold08.Rep1: alpha=1, lambda=1 
## - Fold08.Rep1: alpha=1, lambda=1 
## + Fold09.Rep1: alpha=1, lambda=1 
## - Fold09.Rep1: alpha=1, lambda=1 
## + Fold10.Rep1: alpha=1, lambda=1 
## - Fold10.Rep1: alpha=1, lambda=1 
## Aggregating results
## Selecting tuning parameters
## Fitting alpha = 1, lambda = 0.001 on full training set</code></pre>
<pre class="r"><code>lassoModel &lt;- lassoFit$finalModel</code></pre>
<p>What metric is being used Hint: print <code>names(lassoFit)</code> and get the metric used.</p>
<p>Printing the <code>lassoFit</code> variable gives the overall performance.</p>
<pre class="r"><code>names(lassoFit)</code></pre>
<pre><code>##  [1] &quot;method&quot;       &quot;modelInfo&quot;    &quot;modelType&quot;    &quot;results&quot;     
##  [5] &quot;pred&quot;         &quot;bestTune&quot;     &quot;call&quot;         &quot;dots&quot;        
##  [9] &quot;metric&quot;       &quot;control&quot;      &quot;finalModel&quot;   &quot;preProcess&quot;  
## [13] &quot;trainingData&quot; &quot;resample&quot;     &quot;resampledCM&quot;  &quot;perfNames&quot;   
## [17] &quot;maximize&quot;     &quot;yLimits&quot;      &quot;times&quot;        &quot;levels&quot;</code></pre>
<pre class="r"><code>print(lassoFit)</code></pre>
<pre><code>## glmnet 
## 
## 8641 samples
##   14 predictor
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold, repeated 1 times) 
## Summary of sample sizes: 7777, 7777, 7777, 7777, 7777, 7777, ... 
## Resampling results across tuning parameters:
## 
##   lambda  RMSE  Rsquared  MAE 
##   1e-06   2.21  0.750     1.62
##   1e-05   2.21  0.750     1.62
##   1e-04   2.21  0.750     1.62
##   1e-03   2.21  0.750     1.62
##   1e-02   2.21  0.750     1.62
##   1e-01   2.23  0.744     1.64
##   1e+00   2.51  0.736     2.05
## 
## Tuning parameter &#39;alpha&#39; was held constant at a value of 1
## RMSE was used to select the optimal model using the smallest value.
## The final values used for the model were alpha = 1 and lambda = 0.001.</code></pre>
<ul>
<li>Accuracy per CV-fold (for best model)</li>
</ul>
<pre class="r"><code>print(lassoFit$resample)</code></pre>
<pre><code>##    RMSE Rsquared  MAE    Resample
## 1  2.18    0.760 1.55 Fold07.Rep1
## 2  2.20    0.753 1.61 Fold03.Rep1
## 3  2.25    0.742 1.65 Fold05.Rep1
## 4  2.19    0.752 1.62 Fold02.Rep1
## 5  2.17    0.756 1.61 Fold09.Rep1
## 6  2.30    0.723 1.69 Fold06.Rep1
## 7  2.26    0.737 1.68 Fold08.Rep1
## 8  2.19    0.765 1.60 Fold10.Rep1
## 9  2.13    0.760 1.56 Fold04.Rep1
## 10 2.19    0.752 1.63 Fold01.Rep1</code></pre>
<p>We can inspect the coefficients for different values of the L1 penalty lambda - play around and see what happens.</p>
<pre class="r"><code>print(coef(lassoModel, s=1e-4))</code></pre>
<pre><code>## 15 x 1 sparse Matrix of class &quot;dgCMatrix&quot;
##                   1
## (Intercept) -4.4929
## Control     -0.1595
## Dnase        0.4740
## H2az         0.1990
## H3k27ac     -0.1992
## H3k27me3    -0.5880
## H3k36me3     0.6753
## H3k4me1     -0.0932
## H3k4me2     -0.1460
## H3k4me3      0.3357
## H3k79me2     0.6071
## H3k9ac       0.4594
## H3k9me1     -0.4166
## H3k9me3     -0.1905
## H4k20me1     0.0615</code></pre>
<pre class="r"><code>print(coef(lassoModel, s=1))</code></pre>
<pre><code>## 15 x 1 sparse Matrix of class &quot;dgCMatrix&quot;
##                   1
## (Intercept) -3.6031
## Control      .     
## Dnase        0.3023
## H2az         .     
## H3k27ac      .     
## H3k27me3     .     
## H3k36me3     0.1044
## H3k4me1      .     
## H3k4me2      .     
## H3k4me3      0.0343
## H3k79me2     0.5703
## H3k9ac       0.2765
## H3k9me1      .     
## H3k9me3      .     
## H4k20me1     .</code></pre>
<p>We can also plot the entire regularization path The numbers shown are the feature (column) ids - to get the name of the feature, you can do colnames(features)[10], for instance. the numbers at the top are the numbers of nonzero coefficients.</p>
<pre class="r"><code>plot(lassoModel, &quot;lambda&quot;, label=T)</code></pre>
<p><img src="expression-prediction_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
<p>The final, trained model is in <code>lassoFit</code>. We can plot the predictions vs original targets.</p>
<pre class="r"><code>lassoPreds &lt;- predict(lassoFit, newdata=features)
plot(target, lassoPreds)</code></pre>
<p><img src="expression-prediction_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
</div>
<div id="random-forests" class="section level2">
<h2>Random Forests</h2>
<pre class="r"><code>library(caret)</code></pre>
<pre class="r"><code>rfGrid &lt;- expand.grid(mtry=floor(ncol(features)/3))</code></pre>
<pre class="r"><code>randomforestFit &lt;- train(features, target, method=&quot;rf&quot;, 
                         trControl=fitControl, tuneGrid=rfGrid,
                         ntree=100)</code></pre>
<pre><code>## + Fold01.Rep1: mtry=4 
## - Fold01.Rep1: mtry=4 
## + Fold02.Rep1: mtry=4 
## - Fold02.Rep1: mtry=4 
## + Fold03.Rep1: mtry=4 
## - Fold03.Rep1: mtry=4 
## + Fold04.Rep1: mtry=4 
## - Fold04.Rep1: mtry=4 
## + Fold05.Rep1: mtry=4 
## - Fold05.Rep1: mtry=4 
## + Fold06.Rep1: mtry=4 
## - Fold06.Rep1: mtry=4 
## + Fold07.Rep1: mtry=4 
## - Fold07.Rep1: mtry=4 
## + Fold08.Rep1: mtry=4 
## - Fold08.Rep1: mtry=4 
## + Fold09.Rep1: mtry=4 
## - Fold09.Rep1: mtry=4 
## + Fold10.Rep1: mtry=4 
## - Fold10.Rep1: mtry=4 
## Aggregating results
## Fitting final model on full training set</code></pre>
<pre class="r"><code>rfModel &lt;- randomforestFit$finalModel</code></pre>
<p>The overall accuracy is:</p>
<pre class="r"><code>print(randomforestFit)</code></pre>
<pre><code>## Random Forest 
## 
## 8641 samples
##   14 predictor
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold, repeated 1 times) 
## Summary of sample sizes: 7777, 7776, 7777, 7777, 7777, 7777, ... 
## Resampling results:
## 
##   RMSE  Rsquared  MAE 
##   2.13  0.767     1.51
## 
## Tuning parameter &#39;mtry&#39; was held constant at a value of 4</code></pre>
<p>We can also look at the accuracy per cross-validation fold.</p>
<pre class="r"><code>print(randomforestFit$resample)</code></pre>
<pre><code>##    RMSE Rsquared  MAE    Resample
## 1  2.14    0.758 1.52 Fold01.Rep1
## 2  2.08    0.775 1.44 Fold02.Rep1
## 3  2.08    0.780 1.48 Fold03.Rep1
## 4  2.19    0.747 1.56 Fold04.Rep1
## 5  2.10    0.776 1.49 Fold05.Rep1
## 6  2.19    0.756 1.55 Fold06.Rep1
## 7  2.11    0.772 1.51 Fold07.Rep1
## 8  2.14    0.764 1.51 Fold08.Rep1
## 9  2.23    0.753 1.56 Fold09.Rep1
## 10 2.07    0.788 1.46 Fold10.Rep1</code></pre>
<p>The variable importance gives a measure of the relative contributions of each of the variables (histone marks) to the expression prediction. Larger values reflect greater feature importance.</p>
<pre class="r"><code>print(rfModel$importance[order(rfModel$importance, decreasing=T),])</code></pre>
<pre><code>## H3k79me2   H3k9ac  H3k4me3  H3k27ac    Dnase H3k36me3  H3k4me2     H2az 
##    32437    27788    23553    20887    14632    12402    12054     4668 
## H3k27me3  H3k4me1  H3k9me1 H4k20me1  H3k9me3  Control 
##     3468     3251     2827     2720     2649     2510</code></pre>
<p>The final trained model is in randomforestFit. Again, we can plot the predictions vs original targets.</p>
<pre class="r"><code>randomforestPreds &lt;- predict(randomforestFit, newdata=features)
plot(target, randomforestPreds)</code></pre>
<p><img src="expression-prediction_files/figure-html/unnamed-chunk-19-1.png" width="672" /></p>
</div>
</div>
<div id="further-exploration" class="section level1">
<h1>Further exploration</h1>
<ul>
<li>How does the performance of random forests compare to the lasso? (you can look at the output of print(lassoFit) and print(randomforestFit))</li>
<li><p>How do other models perform? You can try other models by changing the “method” parameter in the “train” call. Some suggestions for models: linear regression, “lm” and regression trees, “rpart2”.</p></li>
<li><p>Construct a proper test set and re-run the analyses</p></li>
<li><p>How do the individual histone marks contribute to the accuracy of the predictions? You can formulate hypotheses about which marks are important and only include those in the feature matrix when learning your model to see how they do. We provide some code below to help you with this.</p></li>
</ul>
<p>We can experiment with the weights that lasso regression produces when given a subset of the features. First, create a column vector specifying the names of a subset of the features with:</p>
<pre class="r"><code>featureSubset &lt;- c(&quot;Control&quot;, &quot;H3k4me1&quot;, &quot;H3k4me2&quot;, &quot;H2az&quot;, &quot;H3k27me3&quot;,
                   &quot;H3k36me3&quot;, &quot;H3k9me1&quot;, &quot;H3k9me3&quot;, &quot;H4k20me1&quot;)</code></pre>
<p>Now create the variable “features” which contains this subset of features:</p>
<pre class="r"><code>features &lt;- fullFeatureSet[featureSubset]</code></pre>
<p>Now, rerun the lasso regression with the subset.</p>
<pre class="r"><code>lassoFit &lt;- train(features, target, method=&quot;glmnet&quot;,
                  trControl=fitControl, tuneGrid=lassoGrid)</code></pre>
<pre><code>## + Fold01.Rep1: alpha=1, lambda=1 
## - Fold01.Rep1: alpha=1, lambda=1 
## + Fold02.Rep1: alpha=1, lambda=1 
## - Fold02.Rep1: alpha=1, lambda=1 
## + Fold03.Rep1: alpha=1, lambda=1 
## - Fold03.Rep1: alpha=1, lambda=1 
## + Fold04.Rep1: alpha=1, lambda=1 
## - Fold04.Rep1: alpha=1, lambda=1 
## + Fold05.Rep1: alpha=1, lambda=1 
## - Fold05.Rep1: alpha=1, lambda=1 
## + Fold06.Rep1: alpha=1, lambda=1 
## - Fold06.Rep1: alpha=1, lambda=1 
## + Fold07.Rep1: alpha=1, lambda=1 
## - Fold07.Rep1: alpha=1, lambda=1 
## + Fold08.Rep1: alpha=1, lambda=1 
## - Fold08.Rep1: alpha=1, lambda=1 
## + Fold09.Rep1: alpha=1, lambda=1 
## - Fold09.Rep1: alpha=1, lambda=1 
## + Fold10.Rep1: alpha=1, lambda=1 
## - Fold10.Rep1: alpha=1, lambda=1 
## Aggregating results
## Selecting tuning parameters
## Fitting alpha = 1, lambda = 0.001 on full training set</code></pre>
<pre class="r"><code>lassoModel &lt;- lassoFit$finalModel</code></pre>
<p>We now generate a plot where the y axis is the coefficient of the weights assigned to the various features by lasso, the bottom x-axis is the log of the regularisation parameter lambda, and the top x-axis is the number of non-zero weights for that particular value of the regularisation parameter. The numbers on the lines correspond to the indices of the features in “featureSubset”. The numbers at the top are the numbers of nonzero betas.</p>
<pre class="r"><code>plot(lassoModel, &quot;lambda&quot;, label=T)</code></pre>
<p><img src="expression-prediction_files/figure-html/unnamed-chunk-23-1.png" width="672" /></p>
</div>

    <script>
        (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
        })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
        ga('create', 'UA-93043521-1', 'auto');
        ga('send', 'pageview');

         
        var links = document.querySelectorAll('a');
        Array.prototype.map.call(links, function(item) {
            if (item.host != document.location.host) {
                item.addEventListener('click', function() {
                    var action = item.getAttribute('data-action') || 'follow';
                    ga('send', 'event', 'outbound', action, item.href);
                });
            }
        });
    </script>


</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
