<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="author" content="Sean Davis" />
  <title>Machine Learning</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="site_libs/reveal.js-3.3.0.1/css/reveal.css"/>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; position: absolute; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; }
pre.numberSource a.sourceLine:empty
  { position: absolute; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: absolute; left: -5em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="site_libs/reveal.js-3.3.0.1/css/theme/simple.css" id="theme">


  <!-- some tweaks to reveal css -->
  <style type="text/css">
    .reveal h1 { font-size: 2.0em; }
    .reveal h2 { font-size: 1.5em;  }
    .reveal h3 { font-size: 1.25em;	}
    .reveal h4 { font-size: 1em;	}

    .reveal .slides>section,
    .reveal .slides>section>section {
      padding: 0px 0px;
    }



    .reveal table {
      border-width: 1px;
      border-spacing: 2px;
      border-style: dotted;
      border-color: gray;
      border-collapse: collapse;
      font-size: 0.7em;
    }

    .reveal table th {
      border-width: 1px;
      padding-left: 10px;
      padding-right: 25px;
      font-weight: bold;
      border-style: dotted;
      border-color: gray;
    }

    .reveal table td {
      border-width: 1px;
      padding-left: 10px;
      padding-right: 25px;
      border-style: dotted;
      border-color: gray;
    }


  </style>

    <style type="text/css">code{white-space: pre;}</style>


<!-- Printing and PDF exports -->
<script id="paper-css" type="application/dynamic-css">

/* Default Print Stylesheet Template
   by Rob Glazebrook of CSSnewbie.com
   Last Updated: June 4, 2008

   Feel free (nay, compelled) to edit, append, and
   manipulate this file as you see fit. */


@media print {

	/* SECTION 1: Set default width, margin, float, and
	   background. This prevents elements from extending
	   beyond the edge of the printed page, and prevents
	   unnecessary background images from printing */
	html {
		background: #fff;
		width: auto;
		height: auto;
		overflow: visible;
	}
	body {
		background: #fff;
		font-size: 20pt;
		width: auto;
		height: auto;
		border: 0;
		margin: 0 5%;
		padding: 0;
		overflow: visible;
		float: none !important;
	}

	/* SECTION 2: Remove any elements not needed in print.
	   This would include navigation, ads, sidebars, etc. */
	.nestedarrow,
	.controls,
	.fork-reveal,
	.share-reveal,
	.state-background,
	.reveal .progress,
	.reveal .backgrounds {
		display: none !important;
	}

	/* SECTION 3: Set body font face, size, and color.
	   Consider using a serif font for readability. */
	body, p, td, li, div {
		font-size: 20pt!important;
		font-family: Georgia, "Times New Roman", Times, serif !important;
		color: #000;
	}

	/* SECTION 4: Set heading font face, sizes, and color.
	   Differentiate your headings from your body text.
	   Perhaps use a large sans-serif for distinction. */
	h1,h2,h3,h4,h5,h6 {
		color: #000!important;
		height: auto;
		line-height: normal;
		font-family: Georgia, "Times New Roman", Times, serif !important;
		text-shadow: 0 0 0 #000 !important;
		text-align: left;
		letter-spacing: normal;
	}
	/* Need to reduce the size of the fonts for printing */
	h1 { font-size: 28pt !important;  }
	h2 { font-size: 24pt !important; }
	h3 { font-size: 22pt !important; }
	h4 { font-size: 22pt !important; font-variant: small-caps; }
	h5 { font-size: 21pt !important; }
	h6 { font-size: 20pt !important; font-style: italic; }

	/* SECTION 5: Make hyperlinks more usable.
	   Ensure links are underlined, and consider appending
	   the URL to the end of the link for usability. */
	a:link,
	a:visited {
		color: #000 !important;
		font-weight: bold;
		text-decoration: underline;
	}
	/*
	.reveal a:link:after,
	.reveal a:visited:after {
		content: " (" attr(href) ") ";
		color: #222 !important;
		font-size: 90%;
	}
	*/


	/* SECTION 6: more reveal.js specific additions by @skypanther */
	ul, ol, div, p {
		visibility: visible;
		position: static;
		width: auto;
		height: auto;
		display: block;
		overflow: visible;
		margin: 0;
		text-align: left !important;
	}
	.reveal pre,
	.reveal table {
		margin-left: 0;
		margin-right: 0;
	}
	.reveal pre code {
		padding: 20px;
		border: 1px solid #ddd;
	}
	.reveal blockquote {
		margin: 20px 0;
	}
	.reveal .slides {
		position: static !important;
		width: auto !important;
		height: auto !important;

		left: 0 !important;
		top: 0 !important;
		margin-left: 0 !important;
		margin-top: 0 !important;
		padding: 0 !important;
		zoom: 1 !important;

		overflow: visible !important;
		display: block !important;

		text-align: left !important;
		-webkit-perspective: none;
		   -moz-perspective: none;
		    -ms-perspective: none;
		        perspective: none;

		-webkit-perspective-origin: 50% 50%;
		   -moz-perspective-origin: 50% 50%;
		    -ms-perspective-origin: 50% 50%;
		        perspective-origin: 50% 50%;
	}
	.reveal .slides section {
		visibility: visible !important;
		position: static !important;
		width: auto !important;
		height: auto !important;
		display: block !important;
		overflow: visible !important;

		left: 0 !important;
		top: 0 !important;
		margin-left: 0 !important;
		margin-top: 0 !important;
		padding: 60px 20px !important;
		z-index: auto !important;

		opacity: 1 !important;

		page-break-after: always !important;

		-webkit-transform-style: flat !important;
		   -moz-transform-style: flat !important;
		    -ms-transform-style: flat !important;
		        transform-style: flat !important;

		-webkit-transform: none !important;
		   -moz-transform: none !important;
		    -ms-transform: none !important;
		        transform: none !important;

		-webkit-transition: none !important;
		   -moz-transition: none !important;
		    -ms-transition: none !important;
		        transition: none !important;
	}
	.reveal .slides section.stack {
		padding: 0 !important;
	}
	.reveal section:last-of-type {
		page-break-after: avoid !important;
	}
	.reveal section .fragment {
		opacity: 1 !important;
		visibility: visible !important;

		-webkit-transform: none !important;
		   -moz-transform: none !important;
		    -ms-transform: none !important;
		        transform: none !important;
	}
	.reveal section img {
		display: block;
		margin: 15px 0px;
		background: rgba(255,255,255,1);
		border: 1px solid #666;
		box-shadow: none;
	}

	.reveal section small {
		font-size: 0.8em;
	}

}  
</script>


<script id="pdf-css" type="application/dynamic-css">
    
/**
 * This stylesheet is used to print reveal.js
 * presentations to PDF.
 *
 * https://github.com/hakimel/reveal.js#pdf-export
 */

* {
	-webkit-print-color-adjust: exact;
}

body {
	margin: 0 auto !important;
	border: 0;
	padding: 0;
	float: none !important;
	overflow: visible;
}

html {
	width: 100%;
	height: 100%;
	overflow: visible;
}

/* Remove any elements not needed in print. */
.nestedarrow,
.reveal .controls,
.reveal .progress,
.reveal .playback,
.reveal.overview,
.fork-reveal,
.share-reveal,
.state-background {
	display: none !important;
}

h1, h2, h3, h4, h5, h6 {
	text-shadow: 0 0 0 #000 !important;
}

.reveal pre code {
	overflow: hidden !important;
	font-family: Courier, 'Courier New', monospace !important;
}

ul, ol, div, p {
	visibility: visible;
	position: static;
	width: auto;
	height: auto;
	display: block;
	overflow: visible;
	margin: auto;
}
.reveal {
	width: auto !important;
	height: auto !important;
	overflow: hidden !important;
}
.reveal .slides {
	position: static;
	width: 100%;
	height: auto;

	left: auto;
	top: auto;
	margin: 0 !important;
	padding: 0 !important;

	overflow: visible;
	display: block;

	-webkit-perspective: none;
	   -moz-perspective: none;
	    -ms-perspective: none;
	        perspective: none;

	-webkit-perspective-origin: 50% 50%; /* there isn't a none/auto value but 50-50 is the default */
	   -moz-perspective-origin: 50% 50%;
	    -ms-perspective-origin: 50% 50%;
	        perspective-origin: 50% 50%;
}

.reveal .slides section {
	page-break-after: always !important;

	visibility: visible !important;
	position: relative !important;
	display: block !important;
	position: relative !important;

	margin: 0 !important;
	padding: 0 !important;
	box-sizing: border-box !important;
	min-height: 1px;

	opacity: 1 !important;

	-webkit-transform-style: flat !important;
	   -moz-transform-style: flat !important;
	    -ms-transform-style: flat !important;
	        transform-style: flat !important;

	-webkit-transform: none !important;
	   -moz-transform: none !important;
	    -ms-transform: none !important;
	        transform: none !important;
}

.reveal section.stack {
	margin: 0 !important;
	padding: 0 !important;
	page-break-after: avoid !important;
	height: auto !important;
	min-height: auto !important;
}

.reveal img {
	box-shadow: none;
}

.reveal .roll {
	overflow: visible;
	line-height: 1em;
}

/* Slide backgrounds are placed inside of their slide when exporting to PDF */
.reveal section .slide-background {
	display: block !important;
	position: absolute;
	top: 0;
	left: 0;
	width: 100%;
	z-index: -1;
}

/* All elements should be above the slide-background */
.reveal section>* {
	position: relative;
	z-index: 1;
}

/* Display slide speaker notes when 'showNotes' is enabled */
.reveal .speaker-notes-pdf {
	display: block;
	width: 100%;
	max-height: none;
	left: auto;
	top: auto;
	z-index: 100;
}

/* Display slide numbers when 'slideNumber' is enabled */
.reveal .slide-number-pdf {
	display: block;
	position: absolute;
	font-size: 14px;
}

</script>


<script>
var style = document.createElement( 'style' );
style.type = 'text/css';
var style_script_id = window.location.search.match( /print-pdf/gi ) ? 'pdf-css' : 'paper-css';
var style_script = document.getElementById(style_script_id).text;
style.innerHTML = style_script;
document.getElementsByTagName('head')[0].appendChild(style);
</script>

</head>
<body>
  <div class="reveal">
    <div class="slides">

<section>
    <h1 class="title">Machine Learning</h1>
  <h1 class="subtitle">A hands-on introduction using R</h1>
    <h2 class="author">Sean Davis</h2>
</section>

<section class="slide level2">

<style type="text/css">
  .reveal p {
    text-align: left;
  }
  .reveal ul {
    display: block;
  }
  .reveal ol {
    display: block;
  }  
</style>
</section>
<section><section id="preliminaries" class="title-slide slide level1"><h1>Preliminaries</h1></section><section id="install-required-libraries." class="slide level2">
<h2>Install required libraries.</h2>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1-1" data-line-number="1">BiocManager<span class="op">::</span><span class="kw">install</span>(<span class="kw">c</span>(<span class="st">&quot;mlbench&quot;</span>, <span class="st">&quot;adabag&quot;</span>, <span class="st">&quot;e1071&quot;</span>, <span class="st">&quot;randomForest&quot;</span>, </a>
<a class="sourceLine" id="cb1-2" data-line-number="2">    <span class="st">&quot;party&quot;</span>, <span class="st">&quot;mboost&quot;</span>, <span class="st">&quot;rpart.plot&quot;</span>, <span class="st">&quot;formatR&quot;</span>))</a></code></pre></div>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb2-1" data-line-number="1"><span class="kw">require</span>(<span class="kw">c</span>(<span class="st">&quot;mlbench&quot;</span>, <span class="st">&quot;adabag&quot;</span>, <span class="st">&quot;e1071&quot;</span>, <span class="st">&quot;randomForest&quot;</span>, <span class="st">&quot;party&quot;</span>, </a>
<a class="sourceLine" id="cb2-2" data-line-number="2">    <span class="st">&quot;mboost&quot;</span>, <span class="st">&quot;rpart.plot&quot;</span>, <span class="st">&quot;formatR&quot;</span>))</a></code></pre></div>
<h3 id="some-links-of-interest">Some links of interest</h3>
<ul>
<li><a href="https://https://cran.r-project.org/package=caret">caret</a>, <a href="https://cran.r-project.org/package=party">party</a>, <a href="https://cran.r-project.org/package=randomForest">randomForest</a>, <a href="https://cran.r-project.org/package=mlbench">mlbench</a>, <a href="https://cran.r-project.org/package=mlr">mlr</a></li>
<li><a href="https://www.r-project.org/conferences/useR-2013/Tutorials/kuhn/user_caret_2up.pdf">Max Kuhn’s old machine learning tutorial</a></li>
</ul>
</section></section>
<section><section id="overview" class="title-slide slide level1"><h1>Overview</h1></section><section id="what-is-machine-learning" class="slide level2">
<h2>What is machine learning?</h2>
<p>Machine learning is a broad set of fields related to computers learning from “experience” (data).</p>
<ul>
<li>Focusing on <em>predictive modeling</em> with a goal of <em>producing the most accurate estimates of some quantity or the most likely output of an event</em>.</li>
<li>These models are sometimes based on similar models for inference (testing against a null hypothesis, such as linear regression), but in many cases, predictive models are not well-suited for inference (think k-nearest-neighbor, for example).</li>
</ul>
</section><section id="the-formula-interface" class="slide level2">
<h2>The formula interface</h2>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb3-1" data-line-number="1">outcome <span class="op">~</span><span class="st"> </span>var1 <span class="op">+</span><span class="st"> </span>var2 <span class="op">+</span><span class="st"> </span>...</a></code></pre></div>
<p>The variable <code>outcome</code> is predicted by <code>var1, var2, ...</code></p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb4-1" data-line-number="1"><span class="kw">some_model_function</span>(price <span class="op">~</span><span class="st"> </span>numBedrooms <span class="op">+</span><span class="st"> </span>numBaths <span class="op">+</span><span class="st"> </span>acres, <span class="dt">data =</span> housingData)</a></code></pre></div>
<p>Conveniences of the formula interface:</p>
<ul>
<li>Transformations such as <code>log10(acres)</code> can be specified inline.</li>
<li>Factors are converted into dummy variables automatically.</li>
</ul>
</section><section id="the-non-formula-interface" class="slide level2">
<h2>The Non-formula interface</h2>
<ul>
<li>The non-formula interface specifies the predictors as a matrix or data frame.</li>
<li>The outcome data are then passed into the model as a vector.</li>
</ul>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb5-1" data-line-number="1"><span class="kw">some_model_function</span>(<span class="dt">x =</span> housePredictors, <span class="dt">y =</span> price)</a></code></pre></div>
<p>Many R functions offer both a formula and a non-formula interface, but not all.</p>
</section><section id="general-workflow-for-machine-learning-in-r" class="slide level2">
<h2>General workflow for machine learning in R</h2>
<ol type="1">
<li><p>Fit the model to a set of training data</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb6-1" data-line-number="1">fit &lt;-<span class="st"> </span><span class="kw">knn</span>(trainingData, outcome, <span class="dt">k =</span> <span class="dv">5</span>)</a></code></pre></div></li>
<li>Assess the properties of the model using <code>print</code>, <code>plot</code>, <code>summary</code> or other methods</li>
<li><p>Predict outcomes for samples using the predict method:</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb7-1" data-line-number="1"><span class="kw">predict</span>(fit, newSamples).</a></code></pre></div></li>
</ol>
</section></section>
<section><section id="exercise-1" class="title-slide slide level1"><h1>Exercise 1</h1></section><section id="is-mpg-a-function-of-wt" class="slide level2 smaller">
<h2>Is <code>mpg</code> a function of <code>wt</code>?</h2>
<p>The formula interface in action:</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb8-1" data-line-number="1"><span class="kw">data</span>(mtcars)</a>
<a class="sourceLine" id="cb8-2" data-line-number="2">fit =<span class="st"> </span><span class="kw">lm</span>(mpg <span class="op">~</span><span class="st"> </span>wt, <span class="dt">data =</span> mtcars)</a>
<a class="sourceLine" id="cb8-3" data-line-number="3"><span class="kw">summary</span>(fit)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = mpg ~ wt, data = mtcars)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -4.543 -2.365 -0.125  1.410  6.873 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   37.285      1.878   19.86  &lt; 2e-16 ***
## wt            -5.344      0.559   -9.56  1.3e-10 ***
## ---
## Signif. codes:  
## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 3.05 on 30 degrees of freedom
## Multiple R-squared:  0.753,  Adjusted R-squared:  0.745 
## F-statistic: 91.4 on 1 and 30 DF,  p-value: 1.29e-10</code></pre>
<p>And make a plot.</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb10-1" data-line-number="1"><span class="kw">plot</span>(mpg <span class="op">~</span><span class="st"> </span>wt, <span class="dt">data =</span> mtcars)</a>
<a class="sourceLine" id="cb10-2" data-line-number="2"><span class="kw">abline</span>(fit)</a></code></pre></div>
</section><section id="is-mpg-a-function-of-wt-1" class="slide level2">
<h2>Is <code>mpg</code> a function of <code>wt</code>?</h2>
<p><img data-src="MachineLearning_files/figure-revealjs/unnamed-chunk-11-1.png" /></p>
</section><section id="use-wt-to-predict-mpg" class="slide level2">
<h2>Use <code>wt</code> to predict <code>mpg</code></h2>
<p>And predict the original data based on the fitted model.</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb11-1" data-line-number="1">pred_mpg =<span class="st"> </span><span class="kw">predict</span>(fit, mtcars)</a>
<a class="sourceLine" id="cb11-2" data-line-number="2"><span class="kw">summary</span>(pred_mpg)</a></code></pre></div>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##     8.3    18.0    19.5    20.1    23.5    29.2</code></pre>
<p>And look at the predicted values:</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb13-1" data-line-number="1"><span class="kw">plot</span>(mpg <span class="op">~</span><span class="st"> </span>wt, <span class="dt">data =</span> mtcars)</a>
<a class="sourceLine" id="cb13-2" data-line-number="2"><span class="kw">abline</span>(fit)</a>
<a class="sourceLine" id="cb13-3" data-line-number="3"><span class="kw">points</span>(<span class="dt">y =</span> pred_mpg, <span class="dt">x =</span> mtcars<span class="op">$</span>wt, <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>)</a></code></pre></div>
</section><section id="use-wt-to-predict-mpg-1" class="slide level2">
<h2>Use <code>wt</code> to predict <code>mpg</code></h2>
<p><img data-src="MachineLearning_files/figure-revealjs/unnamed-chunk-14-1.png" /></p>
</section><section id="quantifying-goodness-of-fit" class="slide level2">
<h2>Quantifying “goodness-of-fit”</h2>
<p><img data-src="MachineLearning_files/figure-revealjs/unnamed-chunk-15-1.png" /></p>
</section><section id="quantifying-goodness-of-fit-1" class="slide level2">
<h2>Quantifying “goodness-of-fit”</h2>
<ul>
<li>Residual Sum of Squares <span class="math display">\[ RSS = \sum_{N} (y_i - f(x_i))^{2} \]</span></li>
</ul>
</section><section id="quantifying-goodness-of-fit-2" class="slide level2">
<h2>Quantifying “goodness-of-fit”</h2>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb14-1" data-line-number="1">rss =<span class="st"> </span><span class="kw">sum</span>((mtcars<span class="op">$</span>mpg <span class="op">-</span><span class="st"> </span><span class="kw">predict</span>(fit, mtcars))<span class="op">^</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb14-2" data-line-number="2">rss</a></code></pre></div>
<pre><code>## [1] 278</code></pre>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb16-1" data-line-number="1"><span class="kw">anova</span>(fit)</a></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: mpg
##           Df Sum Sq Mean Sq F value  Pr(&gt;F)    
## wt         1    848     848    91.4 1.3e-10 ***
## Residuals 30    278       9                    
## ---
## Signif. codes:  
## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
</section><section id="training-versus-testing" class="slide level2">
<h2>Training versus testing</h2>
<ul>
<li>What did we do wrong in quantifying our “goodness-of-fit”?</li>
</ul>
</section></section>
<section><section id="splitting-data-and-model-performance-evaluation" class="title-slide slide level1"><h1>Splitting data and model performance evaluation</h1></section><section id="common-steps-during-training" class="slide level2">
<h2>Common steps during training</h2>
<ul>
<li>estimating model parameters (i.e. training models)</li>
<li>determining the values of tuning parameters that cannot be directly calculated from the data</li>
<li>calculating the performance of the final model that will generalize to new data</li>
</ul>
</section><section id="spending-the-data-to-find-an-optimal-model" class="slide level2">
<h2>Spending the data to find an optimal model?</h2>
<ul>
<li>Split data into training and test data sets</li>
<li><em>Training Set</em>: these data are used to estimate model parameters and to pick the values of the complexity parameter(s) for the model.</li>
<li><em>Test Set (aka validation set)</em>: these data can be used to get an independent assessment of model accuracy. The test data should never be used in any aspect of model training.</li>
</ul>
</section><section id="tradeoffs-in-spending-data" class="slide level2">
<h2>Tradeoffs in spending data</h2>
<p>The more data we spend, the better estimates we’ll get (provided the data is accurate). Given a fixed amount of dat:</p>
<ul>
<li>Too much spent in training won’t allow us to get a good assessment of predictive performance. We may find a model that fits the training data very well, but is not generalizable (over–fitting)</li>
<li>Too much spent in testing won’t allow us to get a good assessment of model parameters</li>
</ul>
</section><section id="example-using-mtcars" class="slide level2">
<h2>Example using <code>mtcars</code></h2>
<p>Using 50% of the data for training and 50% for testing is a place to start.</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb18-1" data-line-number="1"><span class="kw">set.seed</span>(<span class="dv">10</span>)</a>
<a class="sourceLine" id="cb18-2" data-line-number="2">trainIdx =<span class="st"> </span><span class="kw">sample</span>(<span class="dv">1</span><span class="op">:</span><span class="kw">nrow</span>(mtcars), <span class="dv">16</span>)</a>
<a class="sourceLine" id="cb18-3" data-line-number="3">trainDat =<span class="st"> </span>mtcars[trainIdx, ]</a>
<a class="sourceLine" id="cb18-4" data-line-number="4">testDat =<span class="st"> </span>mtcars[<span class="op">-</span>trainIdx, ]</a></code></pre></div>
</section><section id="train-the-model-using-the-training-data" class="slide level2">
<h2>Train the model using the training data</h2>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb19-1" data-line-number="1">fit =<span class="st"> </span><span class="kw">lm</span>(mpg <span class="op">~</span><span class="st"> </span>wt, <span class="dt">data =</span> trainDat)</a>
<a class="sourceLine" id="cb19-2" data-line-number="2"><span class="kw">anova</span>(fit)</a></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: mpg
##           Df Sum Sq Mean Sq F value  Pr(&gt;F)    
## wt         1    360     360      42 1.4e-05 ***
## Residuals 14    120       9                    
## ---
## Signif. codes:  
## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
</section><section id="train-the-model-using-the-training-data-1" class="slide level2">
<h2>Train the model using the training data</h2>
<p><img data-src="MachineLearning_files/figure-revealjs/unnamed-chunk-19-1.png" /></p>
</section><section id="test-our-model-using-the-testing-data" class="slide level2">
<h2>Test our model using the testing data</h2>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb21-1" data-line-number="1">pred_mpg =<span class="st"> </span><span class="kw">predict</span>(fit, testDat)</a>
<a class="sourceLine" id="cb21-2" data-line-number="2">rss =<span class="st"> </span><span class="kw">sum</span>((testDat<span class="op">$</span>mpg <span class="op">-</span><span class="st"> </span>pred_mpg)<span class="op">^</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb21-3" data-line-number="3">rss</a></code></pre></div>
<pre><code>## [1] 181</code></pre>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb23-1" data-line-number="1"><span class="kw">anova</span>(fit)</a></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: mpg
##           Df Sum Sq Mean Sq F value  Pr(&gt;F)    
## wt         1    360     360      42 1.4e-05 ***
## Residuals 14    120       9                    
## ---
## Signif. codes:  
## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
</section><section id="test-our-model-using-the-testing-data-1" class="slide level2">
<h2>Test our model using the testing data</h2>
<p><img data-src="MachineLearning_files/figure-revealjs/unnamed-chunk-21-1.png" /></p>
</section></section>
<section><section id="example-2" class="title-slide slide level1"><h1>Example 2</h1></section><section id="classification-trees" class="slide level2">
<h2>Classification Trees</h2>
<p>As a simple dataset to try with machine learning, we are going to predict the species of <code>iris</code> based on four measurements.</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb25-1" data-line-number="1"><span class="kw">data</span>(iris)</a>
<a class="sourceLine" id="cb25-2" data-line-number="2"><span class="kw">View</span>(iris)</a>
<a class="sourceLine" id="cb25-3" data-line-number="3"><span class="kw">pairs</span>(iris[, <span class="dv">1</span><span class="op">:</span><span class="dv">4</span>], <span class="dt">col =</span> iris<span class="op">$</span>Species)</a></code></pre></div>
</section><section id="iris-data" class="slide level2">
<h2>Iris Data</h2>
<p><img data-src="MachineLearning_files/figure-revealjs/unnamed-chunk-23-1.png" /></p>
</section><section id="another-slide" class="slide level2">
<h2>Another slide</h2>
<p>We can start with a simple learner, a <a href="https://en.wikipedia.org/wiki/Decision_tree_learning">classification tree</a>. This learner requires:</p>
<ul>
<li>A known class for each observation</li>
<li>A set of “features” that will serve a potential predictors</li>
</ul>
<ol type="1">
<li>Start with whole dataset.</li>
<li>Choose features one-at-a-time and look for a value of each variable that ends up with the most homogeneous two groups after splitting on that variable/value.</li>
<li>For each resulting group, repeat step 2 until all remaining groups have only one class in them.</li>
<li>Optionally, “prune” the tree to keep only splits that are “statistically significant”.</li>
</ol>
</section><section id="learning-the-model" class="slide level2">
<h2>Learning the model</h2>
<p>The <code>party</code> package includes a function, <code>ctree</code> to “learn” a tree from data.</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb26-1" data-line-number="1"><span class="kw">library</span>(party)</a>
<a class="sourceLine" id="cb26-2" data-line-number="2">x =<span class="st"> </span><span class="kw">ctree</span>(Species <span class="op">~</span><span class="st"> </span>., <span class="dt">data =</span> iris)</a>
<a class="sourceLine" id="cb26-3" data-line-number="3"><span class="kw">plot</span>(x)</a></code></pre></div>
</section><section id="learning-the-model-1" class="slide level2">
<h2>Learning the model</h2>
<p><img data-src="MachineLearning_files/figure-revealjs/unnamed-chunk-25-1.png" /></p>
</section><section id="checking-the-model" class="slide level2">
<h2>Checking the model</h2>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb27-1" data-line-number="1"><span class="kw">library</span>(caret)</a>
<a class="sourceLine" id="cb27-2" data-line-number="2"><span class="kw">library</span>(e1071)</a>
<a class="sourceLine" id="cb27-3" data-line-number="3">prediction =<span class="st"> </span><span class="kw">predict</span>(x, iris)</a>
<a class="sourceLine" id="cb27-4" data-line-number="4"><span class="kw">table</span>(prediction)</a></code></pre></div>
<pre><code>## prediction
##     setosa versicolor  virginica 
##         50         54         46</code></pre>
<div class="sourceCode" id="cb29"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb29-1" data-line-number="1"><span class="kw">confusionMatrix</span>(iris<span class="op">$</span>Species, prediction)</a></code></pre></div>
<pre><code>## Confusion Matrix and Statistics
## 
##             Reference
## Prediction   setosa versicolor virginica
##   setosa         50          0         0
##   versicolor      0         49         1
##   virginica       0          5        45
## 
## Overall Statistics
##                                         
##                Accuracy : 0.96          
##                  95% CI : (0.915, 0.985)
##     No Information Rate : 0.36          
##     P-Value [Acc &gt; NIR] : &lt;2e-16        
##                                         
##                   Kappa : 0.94          
##                                         
##  Mcnemar&#39;s Test P-Value : NA            
## 
## Statistics by Class:
## 
##                      Class: setosa Class: versicolor
## Sensitivity                  1.000             0.907
## Specificity                  1.000             0.990
## Pos Pred Value               1.000             0.980
## Neg Pred Value               1.000             0.950
## Prevalence                   0.333             0.360
## Detection Rate               0.333             0.327
## Detection Prevalence         0.333             0.333
## Balanced Accuracy            1.000             0.948
##                      Class: virginica
## Sensitivity                     0.978
## Specificity                     0.952
## Pos Pred Value                  0.900
## Neg Pred Value                  0.990
## Prevalence                      0.307
## Detection Rate                  0.300
## Detection Prevalence            0.333
## Balanced Accuracy               0.965</code></pre>
</section><section id="data-splitting-take-2" class="slide level2">
<h2>Data splitting, take 2</h2>
<p>What is the problem with what we just did to determine our prediction accuracy?<br />
To deal with this problem, we can split the dataset into a “training” set and then check our prediction on the other piece of the data, the “test” set.</p>
<div class="sourceCode" id="cb31"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb31-1" data-line-number="1"><span class="kw">set.seed</span>(<span class="dv">42</span>)</a>
<a class="sourceLine" id="cb31-2" data-line-number="2">trainIdx =<span class="st"> </span><span class="kw">sample</span>(<span class="kw">c</span>(<span class="ot">TRUE</span>, <span class="ot">FALSE</span>), <span class="dt">size =</span> <span class="kw">nrow</span>(iris), <span class="dt">prob =</span> <span class="kw">c</span>(<span class="fl">0.2</span>, </a>
<a class="sourceLine" id="cb31-3" data-line-number="3">    <span class="fl">0.8</span>), <span class="dt">replace =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb31-4" data-line-number="4">irisTrain =<span class="st"> </span>iris[trainIdx, ]</a>
<a class="sourceLine" id="cb31-5" data-line-number="5">irisTest =<span class="st"> </span>iris[<span class="op">!</span>trainIdx, ]</a>
<a class="sourceLine" id="cb31-6" data-line-number="6"><span class="kw">nrow</span>(irisTrain)</a></code></pre></div>
<pre><code>## [1] 35</code></pre>
<div class="sourceCode" id="cb33"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb33-1" data-line-number="1"><span class="kw">nrow</span>(irisTest)</a></code></pre></div>
<pre><code>## [1] 115</code></pre>
</section><section id="train-our-tree-on-the-training-set." class="slide level2">
<h2>“train” our tree on the “training” set.</h2>
<div class="sourceCode" id="cb35"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb35-1" data-line-number="1">trainTree =<span class="st"> </span><span class="kw">ctree</span>(Species <span class="op">~</span><span class="st"> </span>., <span class="dt">data =</span> irisTrain)</a>
<a class="sourceLine" id="cb35-2" data-line-number="2"><span class="kw">plot</span>(trainTree)</a></code></pre></div>
<p><img data-src="MachineLearning_files/figure-revealjs/unnamed-chunk-28-1.png" /></p>
</section><section id="train-our-tree-on-the-training-set.-1" class="slide level2">
<h2>“train” our tree on the “training” set.</h2>
<p><img data-src="MachineLearning_files/figure-revealjs/unnamed-chunk-29-1.png" /></p>
</section><section id="test-our-predictions-on-the-training-data" class="slide level2">
<h2>Test our predictions on the “training” data</h2>
<p>And how does our <code>trainTree</code> do at predicting the original classes in the “training” data?</p>
<div class="sourceCode" id="cb36"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb36-1" data-line-number="1">trainPred =<span class="st"> </span><span class="kw">predict</span>(trainTree, irisTrain)</a>
<a class="sourceLine" id="cb36-2" data-line-number="2"><span class="kw">confusionMatrix</span>(irisTrain<span class="op">$</span>Species, trainPred)</a></code></pre></div>
</section><section id="test-our-predictions-on-the-training-data-1" class="slide level2">
<h2>Test our predictions on the “training” data</h2>
<pre><code>## Confusion Matrix and Statistics
## 
##             Reference
## Prediction   setosa versicolor virginica
##   setosa         18          0         0
##   versicolor      0          0         5
##   virginica       0          0        12
## 
## Overall Statistics
##                                         
##                Accuracy : 0.857         
##                  95% CI : (0.697, 0.952)
##     No Information Rate : 0.514         
##     P-Value [Acc &gt; NIR] : 2.28e-05      
##                                         
##                   Kappa : 0.749         
##                                         
##  Mcnemar&#39;s Test P-Value : NA            
## 
## Statistics by Class:
## 
##                      Class: setosa Class: versicolor
## Sensitivity                  1.000                NA
## Specificity                  1.000             0.857
## Pos Pred Value               1.000                NA
## Neg Pred Value               1.000                NA
## Prevalence                   0.514             0.000
## Detection Rate               0.514             0.000
## Detection Prevalence         0.514             0.143
## Balanced Accuracy            1.000                NA
##                      Class: virginica
## Sensitivity                     0.706
## Specificity                     1.000
## Pos Pred Value                  1.000
## Neg Pred Value                  0.783
## Prevalence                      0.486
## Detection Rate                  0.343
## Detection Prevalence            0.343
## Balanced Accuracy               0.853</code></pre>
</section><section id="test-our-predictions-on-the-testing-data" class="slide level2">
<h2>Test our predictions on the “testing” data</h2>
<p>How is our prediction performance now on the “test” data?</p>
<div class="sourceCode" id="cb38"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb38-1" data-line-number="1">testPred =<span class="st"> </span><span class="kw">predict</span>(trainTree, irisTest)</a>
<a class="sourceLine" id="cb38-2" data-line-number="2"><span class="kw">confusionMatrix</span>(irisTest<span class="op">$</span>Species, testPred)</a></code></pre></div>
</section><section id="test-our-predictions-on-the-testing-data-1" class="slide level2">
<h2>Test our predictions on the “testing” data</h2>
<pre><code>## Confusion Matrix and Statistics
## 
##             Reference
## Prediction   setosa versicolor virginica
##   setosa         30          0         2
##   versicolor      0          0        45
##   virginica       0          0        38
## 
## Overall Statistics
##                                         
##                Accuracy : 0.591         
##                  95% CI : (0.496, 0.682)
##     No Information Rate : 0.739         
##     P-Value [Acc &gt; NIR] : 1             
##                                         
##                   Kappa : 0.402         
##                                         
##  Mcnemar&#39;s Test P-Value : NA            
## 
## Statistics by Class:
## 
##                      Class: setosa Class: versicolor
## Sensitivity                  1.000                NA
## Specificity                  0.976             0.609
## Pos Pred Value               0.938                NA
## Neg Pred Value               1.000                NA
## Prevalence                   0.261             0.000
## Detection Rate               0.261             0.000
## Detection Prevalence         0.278             0.391
## Balanced Accuracy            0.988                NA
##                      Class: virginica
## Sensitivity                     0.447
## Specificity                     1.000
## Pos Pred Value                  1.000
## Neg Pred Value                  0.390
## Prevalence                      0.739
## Detection Rate                  0.330
## Detection Prevalence            0.330
## Balanced Accuracy               0.724</code></pre>
</section></section>
<section><section id="example-3" class="title-slide slide level1"><h1>Example 3</h1></section><section id="k-nearest-neighbor" class="slide level2">
<h2>k-nearest-neighbor</h2>
<p>Now, let’s make this harder. We will now look at a dataset that is designed to “foil” classifiers.</p>
<div class="sourceCode" id="cb40"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb40-1" data-line-number="1"><span class="kw">library</span>(mlbench)</a>
<a class="sourceLine" id="cb40-2" data-line-number="2"><span class="kw">set.seed</span>(<span class="dv">1</span>)</a>
<a class="sourceLine" id="cb40-3" data-line-number="3">spiral =<span class="st"> </span><span class="kw">mlbench.spirals</span>(<span class="dv">1000</span>, <span class="dt">sd =</span> <span class="fl">0.1</span>)</a>
<a class="sourceLine" id="cb40-4" data-line-number="4">spiral =<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">x =</span> spiral<span class="op">$</span>x[, <span class="dv">1</span>], <span class="dt">y =</span> spiral<span class="op">$</span>x[, <span class="dv">2</span>], <span class="dt">class =</span> <span class="kw">factor</span>(spiral<span class="op">$</span>classes))</a>
<a class="sourceLine" id="cb40-5" data-line-number="5"><span class="kw">library</span>(ggplot2)</a>
<a class="sourceLine" id="cb40-6" data-line-number="6"><span class="kw">ggplot</span>(spiral, <span class="kw">aes</span>(x, y, <span class="dt">color =</span> class)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_point</span>()</a></code></pre></div>
</section><section id="k-nearest-neighbor-1" class="slide level2">
<h2>k-nearest-neighbor</h2>
<p><img data-src="MachineLearning_files/figure-revealjs/unnamed-chunk-35-1.png" /></p>
</section><section id="without-splitting-data" class="slide level2">
<h2>Without splitting data</h2>
<div class="sourceCode" id="cb41"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb41-1" data-line-number="1"><span class="kw">library</span>(caret)</a>
<a class="sourceLine" id="cb41-2" data-line-number="2">fit =<span class="st"> </span><span class="kw">knn3</span>(class <span class="op">~</span><span class="st"> </span>., <span class="dt">data =</span> spiral)</a>
<a class="sourceLine" id="cb41-3" data-line-number="3"><span class="kw">confusionMatrix</span>(<span class="kw">predict</span>(fit, spiral, <span class="dt">type =</span> <span class="st">&quot;class&quot;</span>), spiral<span class="op">$</span>class)</a></code></pre></div>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction   1   2
##          1 466  30
##          2  34 470
##                                        
##                Accuracy : 0.936        
##                  95% CI : (0.919, 0.95)
##     No Information Rate : 0.5          
##     P-Value [Acc &gt; NIR] : &lt;2e-16       
##                                        
##                   Kappa : 0.872        
##                                        
##  Mcnemar&#39;s Test P-Value : 0.708        
##                                        
##             Sensitivity : 0.932        
##             Specificity : 0.940        
##          Pos Pred Value : 0.940        
##          Neg Pred Value : 0.933        
##              Prevalence : 0.500        
##          Detection Rate : 0.466        
##    Detection Prevalence : 0.496        
##       Balanced Accuracy : 0.936        
##                                        
##        &#39;Positive&#39; Class : 1            
## </code></pre>
</section><section id="cross-validation" class="slide level2">
<h2>Cross-validation</h2>
<p>setup</p>
<div class="sourceCode" id="cb43"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb43-1" data-line-number="1"><span class="kw">library</span>(caret)</a>
<a class="sourceLine" id="cb43-2" data-line-number="2">indxTrain &lt;-<span class="st"> </span><span class="kw">createDataPartition</span>(<span class="dt">y =</span> spiral<span class="op">$</span>class, <span class="dt">p =</span> <span class="fl">0.75</span>, </a>
<a class="sourceLine" id="cb43-3" data-line-number="3">    <span class="dt">list =</span> <span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb43-4" data-line-number="4">training &lt;-<span class="st"> </span>spiral[indxTrain, ]</a>
<a class="sourceLine" id="cb43-5" data-line-number="5">testing &lt;-<span class="st"> </span>spiral[<span class="op">-</span>indxTrain, ]</a>
<a class="sourceLine" id="cb43-6" data-line-number="6">ctrl &lt;-<span class="st"> </span><span class="kw">trainControl</span>(<span class="dt">method =</span> <span class="st">&quot;repeatedcv&quot;</span>, <span class="dt">repeats =</span> <span class="dv">3</span>)</a>
<a class="sourceLine" id="cb43-7" data-line-number="7">knnFit &lt;-<span class="st"> </span><span class="kw">train</span>(class <span class="op">~</span><span class="st"> </span>., <span class="dt">data =</span> training, <span class="dt">method =</span> <span class="st">&quot;knn&quot;</span>, <span class="dt">trControl =</span> ctrl, </a>
<a class="sourceLine" id="cb43-8" data-line-number="8">    <span class="dt">tuneLength =</span> <span class="dv">10</span>)</a></code></pre></div>
</section><section id="cross-validation-1" class="slide level2 smaller">
<h2>Cross-validation</h2>
<pre><code>## k-Nearest Neighbors 
## 
## 750 samples
##   2 predictor
##   2 classes: &#39;1&#39;, &#39;2&#39; 
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold, repeated 3 times) 
## Summary of sample sizes: 674, 675, 675, 674, 675, 675, ... 
## Resampling results across tuning parameters:
## 
##   k   Accuracy  Kappa
##    5  0.929     0.859
##    7  0.931     0.861
##    9  0.928     0.855
##   11  0.928     0.855
##   13  0.926     0.852
##   15  0.926     0.852
##   17  0.926     0.852
##   19  0.924     0.848
##   21  0.924     0.849
##   23  0.925     0.850
## 
## Accuracy was used to select the optimal model using
##  the largest value.
## The final value used for the model was k = 7.</code></pre>
</section></section>
<section><section id="exercise-4" class="title-slide slide level1"><h1>Exercise 4</h1></section><section id="what-is-an-ensemble-of-learners" class="slide level2">
<h2>What is an ensemble of learners?</h2>
<p>In some cases, a machine learning algorithm can have limited predictive power, but using multiple “instances” of such <em>weak learners</em> in combination can produce a good result.</p>
<p>It is probably obvious that a classification tree approach might be problematic for a dataset like the <code>spiral</code> dataset. In this example, we are going to use “boosting” to combine many trees, each with minimal prediction capabilities, into an “ensemble” learner with reasonable good prediction capabilities.</p>
</section><section id="using-trees-to-predict-on-the-spiral-dataset" class="slide level2">
<h2>Using trees to predict on the <code>spiral</code> dataset</h2>
<div class="sourceCode" id="cb45"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb45-1" data-line-number="1"><span class="kw">library</span>(formatR)</a>
<a class="sourceLine" id="cb45-2" data-line-number="2"><span class="kw">library</span>(party)</a>
<a class="sourceLine" id="cb45-3" data-line-number="3">trainIdx =<span class="st"> </span><span class="kw">sample</span>(<span class="kw">c</span>(<span class="ot">TRUE</span>, <span class="ot">FALSE</span>), <span class="kw">nrow</span>(spiral), <span class="dt">replace =</span> <span class="ot">TRUE</span>, </a>
<a class="sourceLine" id="cb45-4" data-line-number="4">    <span class="dt">prob =</span> <span class="kw">c</span>(<span class="fl">0.5</span>, <span class="fl">0.5</span>))</a>
<a class="sourceLine" id="cb45-5" data-line-number="5">spiralTrain =<span class="st"> </span>spiral[trainIdx, ]</a>
<a class="sourceLine" id="cb45-6" data-line-number="6">trainTree =<span class="st"> </span><span class="kw">ctree</span>(class <span class="op">~</span><span class="st"> </span>., spiralTrain)</a></code></pre></div>
</section><section id="using-trees-to-predict-on-the-spiral-dataset-1" class="slide level2">
<h2>Using trees to predict on the <code>spiral</code> dataset</h2>
<p><img data-src="MachineLearning_files/figure-revealjs/unnamed-chunk-40-1.png" /></p>
</section><section id="using-trees-to-predict-on-the-spiral-dataset-2" class="slide level2 smaller">
<h2>Using trees to predict on the <code>spiral</code> dataset</h2>
<p>Training Data</p>
<div class="sourceCode" id="cb46"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb46-1" data-line-number="1">prediction =<span class="st"> </span><span class="kw">predict</span>(trainTree, spiralTrain)</a>
<a class="sourceLine" id="cb46-2" data-line-number="2"><span class="kw">confusionMatrix</span>(spiralTrain<span class="op">$</span>class, prediction)</a></code></pre></div>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction   1   2
##          1 253   0
##          2 192  48
##                                         
##                Accuracy : 0.611         
##                  95% CI : (0.566, 0.654)
##     No Information Rate : 0.903         
##     P-Value [Acc &gt; NIR] : 1             
##                                         
##                   Kappa : 0.204         
##                                         
##  Mcnemar&#39;s Test P-Value : &lt;2e-16        
##                                         
##             Sensitivity : 0.569         
##             Specificity : 1.000         
##          Pos Pred Value : 1.000         
##          Neg Pred Value : 0.200         
##              Prevalence : 0.903         
##          Detection Rate : 0.513         
##    Detection Prevalence : 0.513         
##       Balanced Accuracy : 0.784         
##                                         
##        &#39;Positive&#39; Class : 1             
## </code></pre>
</section><section id="using-trees-to-predict-on-the-spiral-dataset-3" class="slide level2 smaller">
<h2>Using trees to predict on the <code>spiral</code> dataset</h2>
<p>Testing data</p>
<div class="sourceCode" id="cb48"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb48-1" data-line-number="1">spiralTest =<span class="st"> </span>spiral[<span class="op">!</span>trainIdx, ]</a>
<a class="sourceLine" id="cb48-2" data-line-number="2">prediction =<span class="st"> </span><span class="kw">predict</span>(trainTree, spiralTest)</a>
<a class="sourceLine" id="cb48-3" data-line-number="3"><span class="kw">confusionMatrix</span>(spiralTest<span class="op">$</span>class, prediction)</a></code></pre></div>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction   1   2
##          1 246   1
##          2 211  49
##                                         
##                Accuracy : 0.582         
##                  95% CI : (0.538, 0.625)
##     No Information Rate : 0.901         
##     P-Value [Acc &gt; NIR] : 1             
##                                         
##                   Kappa : 0.181         
##                                         
##  Mcnemar&#39;s Test P-Value : &lt;2e-16        
##                                         
##             Sensitivity : 0.538         
##             Specificity : 0.980         
##          Pos Pred Value : 0.996         
##          Neg Pred Value : 0.188         
##              Prevalence : 0.901         
##          Detection Rate : 0.485         
##    Detection Prevalence : 0.487         
##       Balanced Accuracy : 0.759         
##                                         
##        &#39;Positive&#39; Class : 1             
## </code></pre>
</section><section id="using-trees-to-predict-on-the-spiral-dataset-4" class="slide level2">
<h2>Using trees to predict on the <code>spiral</code> dataset</h2>
<p>Many trees have similar prediction capability, but each is really bad. This is a characteristic of a “weak learner”. Here, we see that in action by performing a bootstrap sampling (resample with replacement), train, plot, and check prediction accuracy.</p>
</section><section id="using-trees-to-predict-on-the-spiral-dataset-5" class="slide level2">
<h2>Using trees to predict on the <code>spiral</code> dataset</h2>
<p>Must be run “locally” to see effect.</p>
<div class="sourceCode" id="cb50"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb50-1" data-line-number="1">plotBootSample =<span class="st"> </span><span class="cf">function</span>(spiral) {</a>
<a class="sourceLine" id="cb50-2" data-line-number="2">    trainIdx =<span class="st"> </span><span class="kw">sample</span>(<span class="dv">1</span><span class="op">:</span><span class="kw">nrow</span>(spiral), <span class="dt">replace =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb50-3" data-line-number="3">    spiralTrain =<span class="st"> </span>spiral[trainIdx, ]</a>
<a class="sourceLine" id="cb50-4" data-line-number="4">    trainTree =<span class="st"> </span><span class="kw">ctree</span>(class <span class="op">~</span><span class="st"> </span>., spiralTrain)</a>
<a class="sourceLine" id="cb50-5" data-line-number="5">    <span class="kw">plot</span>(trainTree)</a>
<a class="sourceLine" id="cb50-6" data-line-number="6">    spiralTest =<span class="st"> </span>spiral[<span class="op">-</span>trainIdx, ]</a>
<a class="sourceLine" id="cb50-7" data-line-number="7">    prediction =<span class="st"> </span><span class="kw">predict</span>(trainTree, spiralTest)</a>
<a class="sourceLine" id="cb50-8" data-line-number="8">    <span class="kw">print</span>(<span class="kw">confusionMatrix</span>(spiralTest<span class="op">$</span>class, prediction)<span class="op">$</span>overall[<span class="st">&quot;Accuracy&quot;</span>])</a>
<a class="sourceLine" id="cb50-9" data-line-number="9">}</a></code></pre></div>
<div class="sourceCode" id="cb51"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb51-1" data-line-number="1"><span class="co"># press &#39;ESC&#39; or &#39;ctrl-c&#39; to stop</span></a>
<a class="sourceLine" id="cb51-2" data-line-number="2"><span class="cf">while</span> (<span class="ot">TRUE</span>) {</a>
<a class="sourceLine" id="cb51-3" data-line-number="3">    <span class="kw">par</span>(<span class="dt">ask =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb51-4" data-line-number="4">    <span class="kw">plotBootSample</span>(spiral)</a>
<a class="sourceLine" id="cb51-5" data-line-number="5">}</a></code></pre></div>
</section><section id="boosting" class="slide level2">
<h2>Boosting</h2>
<p>We can “combine” a bunch of “weak learners”, giving more “weight” to hard-to-classify observations as we build each new classifier. In this case, we will be using the same classification tree approach again.</p>
<div class="sourceCode" id="cb52"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb52-1" data-line-number="1"><span class="kw">library</span>(adabag)</a>
<a class="sourceLine" id="cb52-2" data-line-number="2">trainIdx =<span class="st"> </span><span class="kw">sample</span>(<span class="kw">c</span>(<span class="ot">TRUE</span>, <span class="ot">FALSE</span>), <span class="kw">nrow</span>(spiral), <span class="dt">replace =</span> <span class="ot">TRUE</span>, </a>
<a class="sourceLine" id="cb52-3" data-line-number="3">    <span class="dt">prob =</span> <span class="kw">c</span>(<span class="fl">0.5</span>, <span class="fl">0.5</span>))</a>
<a class="sourceLine" id="cb52-4" data-line-number="4">spiralTrain =<span class="st"> </span>spiral[trainIdx, ]</a>
<a class="sourceLine" id="cb52-5" data-line-number="5">boostTree =<span class="st"> </span><span class="kw">boosting</span>(class <span class="op">~</span><span class="st"> </span>x <span class="op">+</span><span class="st"> </span>y, <span class="dt">data =</span> spiralTrain, <span class="dt">control =</span> <span class="kw">rpart.control</span>(<span class="dt">maxdepth =</span> <span class="dv">2</span>))</a>
<a class="sourceLine" id="cb52-6" data-line-number="6">prediction =<span class="st"> </span><span class="kw">predict</span>(boostTree, spiralTrain)</a></code></pre></div>
</section><section id="boosting-results" class="slide level2 smaller">
<h2>Boosting results</h2>
</section><section id="a-few-trees-from-our-ensemble" class="slide level2">
<h2>A few trees from our ensemble</h2>
<p><img data-src="MachineLearning_files/figure-revealjs/treeplot-1.png" /></p>
</section><section id="boosted-trees-on-test-data" class="slide level2">
<h2>Boosted trees on test data</h2>
<div class="sourceCode" id="cb53"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb53-1" data-line-number="1">spiralTest =<span class="st"> </span>spiral[<span class="op">!</span>trainIdx, ]</a>
<a class="sourceLine" id="cb53-2" data-line-number="2">prediction =<span class="st"> </span><span class="kw">predict</span>(boostTree, spiralTest)</a>
<a class="sourceLine" id="cb53-3" data-line-number="3"><span class="kw">confusionMatrix</span>(spiralTest<span class="op">$</span>class, <span class="kw">as.factor</span>(prediction<span class="op">$</span>class))</a></code></pre></div>
</section><section id="boosted-trees-on-test-data-1" class="slide level2">
<h2>Boosted trees on test data</h2>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction   1   2
##          1 236  11
##          2  29 218
##                                         
##                Accuracy : 0.919         
##                  95% CI : (0.891, 0.942)
##     No Information Rate : 0.536         
##     P-Value [Acc &gt; NIR] : &lt; 2e-16       
##                                         
##                   Kappa : 0.838         
##                                         
##  Mcnemar&#39;s Test P-Value : 0.00719       
##                                         
##             Sensitivity : 0.891         
##             Specificity : 0.952         
##          Pos Pred Value : 0.955         
##          Neg Pred Value : 0.883         
##              Prevalence : 0.536         
##          Detection Rate : 0.478         
##    Detection Prevalence : 0.500         
##       Balanced Accuracy : 0.921         
##                                         
##        &#39;Positive&#39; Class : 1             
## </code></pre>
</section></section>
<section><section id="exercise-5" class="title-slide slide level1"><h1>Exercise 5</h1></section><section id="random-forests" class="slide level2">
<h2>Random Forests</h2>
<div class="sourceCode" id="cb55"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb55-1" data-line-number="1"><span class="kw">library</span>(randomForest)</a>
<a class="sourceLine" id="cb55-2" data-line-number="2">res =<span class="st"> </span><span class="kw">randomForest</span>(Species <span class="op">~</span><span class="st"> </span>., <span class="dt">data =</span> iris)</a>
<a class="sourceLine" id="cb55-3" data-line-number="3">res</a></code></pre></div>
<pre><code>## 
## Call:
##  randomForest(formula = Species ~ ., data = iris) 
##                Type of random forest: classification
##                      Number of trees: 500
## No. of variables tried at each split: 2
## 
##         OOB estimate of  error rate: 4%
## Confusion matrix:
##            setosa versicolor virginica class.error
## setosa         50          0         0        0.00
## versicolor      0         47         3        0.06
## virginica       0          3        47        0.06</code></pre>
</section></section>
<section><section id="sessioninfo" class="title-slide slide level1"><h1>sessionInfo</h1></section><section id="sessioninfo-1" class="slide level2">
<h2>sessionInfo</h2>
<pre><code>## R Under development (unstable) (2019-01-14 r75992)
## Platform: x86_64-apple-darwin15.6.0 (64-bit)
## Running under: macOS Mojave 10.14.2
## 
## Matrix products: default
## BLAS: /Library/Frameworks/R.framework/Versions/3.6/Resources/lib/libRblas.0.dylib
## LAPACK: /Library/Frameworks/R.framework/Versions/3.6/Resources/lib/libRlapack.dylib
## 
## locale:
## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
## 
## attached base packages:
##  [1] grid      stats4    parallel  stats     graphics 
##  [6] grDevices utils     datasets  methods   base     
## 
## other attached packages:
##  [1] randomForest_4.6-14              
##  [2] rpart.plot_3.0.7                 
##  [3] adabag_4.2                       
##  [4] doParallel_1.0.14                
##  [5] iterators_1.0.10                 
##  [6] foreach_1.4.4                    
##  [7] rpart_4.1-15                     
##  [8] formatR_1.7                      
##  [9] mlbench_2.1-1                    
## [10] e1071_1.7-2                      
## [11] caret_6.0-84                     
## [12] lattice_0.20-38                  
## [13] party_1.3-3                      
## [14] strucchange_1.5-1                
## [15] sandwich_2.5-1                   
## [16] zoo_1.8-6                        
## [17] modeltools_0.2-22                
## [18] mvtnorm_1.0-11                   
## [19] GEOquery_2.53.0                  
## [20] tximport_1.13.6                  
## [21] GenomicFeatures_1.37.3           
## [22] GSE5859_1.0                      
## [23] tissuesGeneExpression_1.0        
## [24] dplyr_0.8.1                      
## [25] rafalib_1.0.0                    
## [26] usethis_1.5.0                    
## [27] devtools_2.0.2                   
## [28] airway_1.5.0                     
## [29] SummarizedExperiment_1.15.5      
## [30] DelayedArray_0.11.2              
## [31] BiocParallel_1.19.0              
## [32] matrixStats_0.54.0               
## [33] nycflights13_1.0.0               
## [34] ggplot2_3.2.0                    
## [35] knitr_1.23                       
## [36] BSgenome.Hsapiens.UCSC.hg19_1.4.0
## [37] BSgenome_1.53.0                  
## [38] Biostrings_2.53.0                
## [39] XVector_0.25.0                   
## [40] AnnotationDbi_1.47.0             
## [41] Biobase_2.45.0                   
## [42] rtracklayer_1.45.1               
## [43] GenomicRanges_1.37.14            
## [44] GenomeInfoDb_1.21.1              
## [45] IRanges_2.19.10                  
## [46] S4Vectors_0.23.17                
## [47] AnnotationHub_2.17.3             
## [48] BiocFileCache_1.9.1              
## [49] dbplyr_1.4.2                     
## [50] BiocGenerics_0.31.4              
## [51] BiocStyle_2.13.2                 
## 
## loaded via a namespace (and not attached):
##   [1] backports_1.1.4              
##   [2] plyr_1.8.4                   
##   [3] lazyeval_0.2.2               
##   [4] splines_3.6.0                
##   [5] TH.data_1.0-10               
##   [6] digest_0.6.19                
##   [7] htmltools_0.3.6              
##   [8] fansi_0.4.0                  
##   [9] magrittr_1.5                 
##  [10] memoise_1.1.0                
##  [11] limma_3.41.5                 
##  [12] remotes_2.1.0                
##  [13] recipes_0.1.5                
##  [14] readr_1.3.1                  
##  [15] gower_0.2.1                  
##  [16] prettyunits_1.0.2            
##  [17] colorspace_1.4-1             
##  [18] blob_1.1.1                   
##  [19] rappdirs_0.3.1               
##  [20] xfun_0.8                     
##  [21] callr_3.2.0                  
##  [22] crayon_1.3.4                 
##  [23] RCurl_1.95-4.12              
##  [24] libcoin_1.0-4                
##  [25] zeallot_0.1.0                
##  [26] survival_2.44-1.1            
##  [27] glue_1.3.1                   
##  [28] gtable_0.3.0                 
##  [29] ipred_0.9-9                  
##  [30] zlibbioc_1.31.0              
##  [31] pkgbuild_1.0.3               
##  [32] scales_1.0.0                 
##  [33] DBI_1.0.0                    
##  [34] Rcpp_1.0.1                   
##  [35] xtable_1.8-4                 
##  [36] progress_1.2.2               
##  [37] bit_1.1-14                   
##  [38] lava_1.6.5                   
##  [39] prodlim_2018.04.18           
##  [40] httr_1.4.0                   
##  [41] revealjs_0.9                 
##  [42] RColorBrewer_1.1-2           
##  [43] pkgconfig_2.0.2              
##  [44] XML_3.98-1.20                
##  [45] nnet_7.3-12                  
##  [46] utf8_1.1.4                   
##  [47] reshape2_1.4.3               
##  [48] tidyselect_0.2.5             
##  [49] labeling_0.3                 
##  [50] rlang_0.4.0                  
##  [51] later_0.8.0                  
##  [52] munsell_0.5.0                
##  [53] tools_3.6.0                  
##  [54] cli_1.1.0                    
##  [55] generics_0.0.2               
##  [56] RSQLite_2.1.1                
##  [57] evaluate_0.14                
##  [58] stringr_1.4.0                
##  [59] yaml_2.2.0                   
##  [60] ModelMetrics_1.2.2           
##  [61] processx_3.3.1               
##  [62] bit64_0.9-7                  
##  [63] fs_1.3.1                     
##  [64] purrr_0.3.2                  
##  [65] coin_1.3-0                   
##  [66] nlme_3.1-140                 
##  [67] mime_0.7                     
##  [68] xml2_1.2.0                   
##  [69] biomaRt_2.41.3               
##  [70] compiler_3.6.0               
##  [71] curl_3.3                     
##  [72] interactiveDisplayBase_1.23.0
##  [73] testthat_2.1.1               
##  [74] tibble_2.1.3                 
##  [75] stringi_1.4.3                
##  [76] highr_0.8                    
##  [77] ps_1.3.0                     
##  [78] desc_1.2.0                   
##  [79] Matrix_1.2-17                
##  [80] vctrs_0.1.0                  
##  [81] pillar_1.4.1                 
##  [82] BiocManager_1.30.4           
##  [83] data.table_1.12.2            
##  [84] bitops_1.0-6                 
##  [85] httpuv_1.5.1                 
##  [86] R6_2.4.0                     
##  [87] bookdown_0.11                
##  [88] promises_1.0.1               
##  [89] sessioninfo_1.1.1            
##  [90] codetools_0.2-16             
##  [91] MASS_7.3-51.4                
##  [92] assertthat_0.2.1             
##  [93] pkgload_1.0.2                
##  [94] rprojroot_1.3-2              
##  [95] withr_2.1.2                  
##  [96] GenomicAlignments_1.21.3     
##  [97] Rsamtools_2.1.2              
##  [98] multcomp_1.4-10              
##  [99] GenomeInfoDbData_1.2.1       
## [100] hms_0.4.2                    
## [101] timeDate_3043.102            
## [102] class_7.3-15                 
## [103] tidyr_0.8.3                  
## [104] rmarkdown_1.13               
## [105] lubridate_1.7.4              
## [106] shiny_1.3.2</code></pre>
<pre><code>&lt;script&gt;
    (function(i,s,o,g,r,a,m){i[&#39;GoogleAnalyticsObject&#39;]=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,&#39;script&#39;,&#39;https://www.google-analytics.com/analytics.js&#39;,&#39;ga&#39;);
    ga(&#39;create&#39;, &#39;UA-93043521-1&#39;, &#39;auto&#39;);
    ga(&#39;send&#39;, &#39;pageview&#39;);


    var links = document.querySelectorAll(&#39;a&#39;);
    Array.prototype.map.call(links, function(item) {
        if (item.host != document.location.host) {
            item.addEventListener(&#39;click&#39;, function() {
                var action = item.getAttribute(&#39;data-action&#39;) || &#39;follow&#39;;
                ga(&#39;send&#39;, &#39;event&#39;, &#39;outbound&#39;, action, item.href);
            });
        }
    });
&lt;/script&gt;</code></pre>
</section></section>
    </div>
  </div>

  <script src="site_libs/reveal.js-3.3.0.1/lib/js/head.min.js"></script>
  <script src="site_libs/reveal.js-3.3.0.1/js/reveal.js"></script>

  <script>

      // Full list of configuration options available at:
      // https://github.com/hakimel/reveal.js#configuration
      Reveal.initialize({
        // Display the page number of the current slide
        slideNumber: true,
        // Push each slide change to the browser history
        history: true,
        // Vertical centering of slides
        center: false,
        // Opens links in an iframe preview overlay
        previewLinks: true,
        // Transition style
        transition: 'default', // none/fade/slide/convex/concave/zoom
        // Transition style for full page slide backgrounds
        backgroundTransition: 'default', // none/fade/slide/convex/concave/zoom



        // Optional reveal.js plugins
        dependencies: [
        ]
      });
    </script>
  <!-- dynamically load mathjax for compatibility with self-contained -->
  <script>
    (function () {
      var script = document.createElement("script");
      script.type = "text/javascript";
      script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
      document.getElementsByTagName("head")[0].appendChild(script);
    })();
  </script>

<script>
  (function() {
    if (window.jQuery) {
      Reveal.addEventListener( 'slidechanged', function(event) {  
        window.jQuery(event.previousSlide).trigger('hidden');
        window.jQuery(event.currentSlide).trigger('shown');
      });
    }
  })();
</script>


  </body>
</html>
